launch_info_file: ./launch_info.json
worker_instances: 4

debug: True
use_cuda: True
pretrained: True

# instead of num_epochs, num_batches is the amount of batches used to train
num_batches: 3125
batch_size: 16
lr: 1.25e-4
# in 'units' of batches
lr_step_size: 2000
weight_decay: 1.0e-3

# increase difficulty when trainings loss is below threshold
loss_threshold: 3.0
# decrease difficulty if too high
max_train_step: 3

# assume difficulty depending on number and types of objects 
# in the scene, class distribution initially uniform  
# define starting point with minimum difficulty 
num_objects = 5

# define how difficulty levels are increased or decreased
# constraint: num_objects <= n_max 
objects_step: 2

# we start with a class distribution of equal weights
# and adjust the class distribution to favor weakest classes
# thus increasing difficulty (else we use uniform distribution) 
distribution_step: 1 

# in 'units' of batches
# amount of training batches after which evaluation step is performed
val_interval: 256
# amount of batches to use for each evaluation step
# note: not included in 'num_batches', thus total number
# of generated data batches will be higher than 'num_batches'
val_len: 32
save_interval: 1024
train_vis_interval: 100
val_vis_interval: 10

model_folder: ./models
best_model_tag: best_model
model_tag: model_batch
model_last_tag: model_last
model_path_to_load: ./models/best_model.pth

# Folder to save visualizations for debugging
debug_path: ./debug

# for inference, BOP data, TLessDataset
inference_path: /mnt/data/tless_test_real/test_primesense

model_score_threshold: 0.3
render_detections: False
detection_folder: ./detection
evaluation_folder: ./evaluation
# use top-k scores for detection
k: 25

bbox_visibility_threshold: 0.30
down_ratio: 4
mean: [0.485, 0.456, 0.406]
std: [0.229, 0.224, 0.225]
h: 512
w: 512
num_classes: 6
n_max: 25
